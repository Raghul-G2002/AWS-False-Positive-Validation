# -*- coding: utf-8 -*-
"""FalseAWSKeyDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FpgYyB8tWVNGmwcvGNaZAdzpb_LZkJSw

# False AWS Key Detection using Logistic Regression

## Detecting whether the given Input is False AWS Key or Not

### Necessary Imports
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegressionCV
from sklearn.feature_selection import SelectKBest, chi2
import pickle
import plotly.express as px
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
from sklearn import metrics
# %matplotlib inline

"""### Reading the dataset """

dataset = pd.read_csv('FalseAWSKeyDataset.csv')
dataset.head()

"""### Plot to analyse how many entries are there"""

dataset.groupby('Label').count().plot.bar(ylim=0)
plt.show()

"""### Creating a vectorizer 
#### Converting the data into an array to do feature extraction
"""

vectorizer = TfidfVectorizer(min_df= 1,max_df = 10, stop_words="english", sublinear_tf=True, norm='l2', ngram_range=(1, 2))
final_features = vectorizer.fit_transform(dataset['Data'].values.astype('U')).toarray()
final_features.shape

"""## Taking the features from the Dataset to train the Model """

X = dataset['Data']
Y = dataset['Label']
X_train, X_test, y_train,y_test= train_test_split(X, Y,test_size=0.2)


# Printing the X_train and Y_train
print(X_train)
print(y_train)
print(X_test)

"""## Creating the Classifier logreg
#### Here Logisitc Regression is used as a classifier to classify the features
#### CV - Cross Validation to avoid Overfitting of Model

"""

logreg = LogisticRegressionCV(cv =3,random_state=0)
pipeline = Pipeline([('vect', vectorizer),
                         ('chi',  SelectKBest(chi2, k='all')),
                         ('clf', logreg)])

model = pipeline.fit(X_train.astype('U'), y_train.astype('U'))
with open('LogisticRegression.pickle', 'wb') as f:
    pickle.dump(model, f)


ytest = np.array(y_test)
print(ytest)
labels = model.predict(X_test.astype('U'))

print(model.predict(['patIsCashlineSummaryAreTxnHistoryEnabled']))

"""## Printing the Classification Report ( Precision, Recall, Accuracy, Max AVG, Min AVG)"""

# confusion matrix and classification report(precision, recall, F1-score)
print(classification_report(ytest.astype('U'), model.predict(X_test.astype('U'))))
cf_matrix = confusion_matrix(ytest.astype('U'), model.predict(X_test.astype('U')))
print(confusion_matrix(ytest.astype('U'), model.predict(X_test.astype('U'))))

"""# Confusion Matrix"""

class_names=[0,1] # name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cf_matrix), annot=True, cmap="BuPu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

"""# Testing the Model

# Checking with the Custom Input

# Final Classification Report
"""

def predict_category(s,train = X_train,model = model):
  predicted = model.predict([s])
  print(predicted)

predict_category("catIsCashlineSummaryAreTxnHistoryEnabled")